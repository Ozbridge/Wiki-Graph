{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "def parser(xmlInput):   # extracts pageid, title and text\n",
    "    myroot = ET.fromstring(xmlInput)\n",
    "    pageid, title, text = '', '', ''\n",
    "    for x in myroot:\n",
    "        if x.tag == 'revision':\n",
    "            for y in x:\n",
    "                if y.tag == 'text':\n",
    "                    text = y.text\n",
    "                    break;\n",
    "        elif x.tag == 'id':\n",
    "            pageid = x.text\n",
    "        elif x.tag == 'title':\n",
    "            title = x.text\n",
    "    return pageid, title.strip().lower(), text\n",
    "\n",
    "def parserRedirect(xmlInput):   # extracts redirect title if it exists\n",
    "    myroot = ET.fromstring(xmlInput)\n",
    "    title, redtitle = '', '#####'\n",
    "    for x in myroot:    # traversing xml tree\n",
    "        if x.tag == 'redirect':\n",
    "            for y, z in x.attrib.items():\n",
    "                if y == 'title':\n",
    "                    redtitle = z\n",
    "                    break\n",
    "        elif x.tag == 'title':\n",
    "            title = x.text\n",
    "    return title.strip().lower(), redtitle.strip().lower()\n",
    "\n",
    "def getLinksList(text):     # extracts wikilink references from text\n",
    "    if text is None:\n",
    "        return []\n",
    "    ret = re.findall(\"\\[\\[[^\\[\\]\\{\\}:\\\\\\/]+]]\", text)    # matches [[pagename]], pagename does not contain ':', '\\', '/'\n",
    "    actret = []     # list to return\n",
    "    for i in range(len(ret)):\n",
    "        temp = ''\n",
    "        for ch in ret[i]:\n",
    "            if ch in ['|', ',', '#']:   # ignoring text after these because page title is complete\n",
    "                break\n",
    "            if ch != '[' and ch != ']':     # ignoring [[]]\n",
    "                temp += ch\n",
    "        temp = temp.lower().replace('\\n', ' ')\n",
    "        temp = ' '.join(temp.split())\n",
    "        if temp != '':\n",
    "            actret.append(temp)\n",
    "    return actret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combines page titles to the main page that they redirect to\n",
    "import bz2\n",
    "alias = dict()\n",
    "aliasfile = open('alias.txt', 'w')      # wrties output here\n",
    "fd = bz2.open('./data/enwiki-latest-pages-articles.xml.bz2', 'r')\n",
    "for i in range(1, 41):\n",
    "    fd.readline()\n",
    "cnt = 0\n",
    "aliascount = 0\n",
    "while True:\n",
    "    xml = ''\n",
    "    line = fd.readline().decode()\n",
    "    cnt += 1\n",
    "    if '<page>' not in line:  # end of file reached\n",
    "        break\n",
    "    while '</page>' not in line:\n",
    "        xml += line.strip() + '\\n'\n",
    "        line = fd.readline().decode()\n",
    "    xml += line.strip() + '\\n'\n",
    "    title, rdtitle = parserRedirect(xml)  # processing xml of the current page\n",
    "    if title != '' and rdtitle != '' and rdtitle != '#####':  # page redirects to another page\n",
    "        aliascount += 1\n",
    "        alias[title] = rdtitle\n",
    "        aliasfile.write(title + '\\n' + rdtitle + '\\n')      # write to alias.txt\n",
    "    if cnt % 10000 == 0:    # progress update\n",
    "        print(cnt, aliascount)\n",
    "aliasfile.close()\n",
    "fd.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "fd = bz2.open('./data/enwiki-latest-pages-articles.xml.bz2', 'r')\n",
    "for i in range(1, 41):\n",
    "    fd.readline()\n",
    "edgefile = open('edges.txt', 'w')\n",
    "cnt = 0\n",
    "lines = 0\n",
    "pagenumber = dict()\n",
    "while True:     # adds all edges to edges.txt\n",
    "    xml = ''\n",
    "    line = fd.readline().decode()\n",
    "    if '<page>' not in line:    # end of file reached\n",
    "        break\n",
    "    while '</page>' not in line :\n",
    "        xml += line.strip()+'\\n'\n",
    "        line = fd.readline().decode()\n",
    "    xml += line.strip()+'\\n'\n",
    "    pageid, title, text = parser(xml)\n",
    "    if re.fullmatch(\"[^\\[\\]\\{\\}:\\\\\\/]+\", title) is None:     # check if current page is valid\n",
    "        continue\n",
    "    links = getLinksList(text)  # get all links of the page\n",
    "    edgefile.write(title+'\\n')  # write the current page once\n",
    "    lines += 1\n",
    "    for link in links:  # write all children\n",
    "        edgefile.write(link+'\\n')\n",
    "        lines += 1\n",
    "    edgefile.write('###\\n')     # current node done\n",
    "    lines += 1\n",
    "    if cnt % 10000 == 0:    # progress update\n",
    "        print(cnt, lines)\n",
    "    cnt += 1\n",
    "print(lines)\n",
    "fd.close()\n",
    "edgefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adjlist = dict()\n",
    "alias = dict()\n",
    "nodeid = dict()\n",
    "nodename = dict()\n",
    "allnodes = dict()\n",
    "visits = dict()\n",
    "aliasfile = open('alias.txt', 'r')\n",
    "edgefile = open('edges.txt', 'r')\n",
    "\n",
    "def init():     # loads the graph into memory\n",
    "    print('loading graph into memory')\n",
    "    aliascount = 0\n",
    "    while True:     # links pages that redirect to another page\n",
    "        title = aliasfile.readline().strip()\n",
    "        if title == '':\n",
    "            break\n",
    "        rdtitle = aliasfile.readline().strip()\n",
    "        alias[title] = rdtitle\n",
    "        aliascount += 1\n",
    "        if aliascount % 10000 == 0:\n",
    "            print('alias count: ' + str(aliascount))\n",
    "    print('loading edges...')\n",
    "    cnt = 0\n",
    "    last = 0\n",
    "    while True:     # loads edges into memory\n",
    "        u = edgefile.readline().strip()\n",
    "        if u == '':\n",
    "            break\n",
    "        if alias.get(u) is not None:    # if page redirects to another page\n",
    "            u = alias[u]\n",
    "        if nodeid.get(u) is None:   # assigning unique id to page for performance\n",
    "            nodeid[u] = last\n",
    "            nodename[last] = u\n",
    "            last += 1\n",
    "        cnt += 1\n",
    "        u = nodeid[u]\n",
    "        if adjlist.get(u) is None:\n",
    "            adjlist[u] = []\n",
    "        v = edgefile.readline().strip()\n",
    "        cnt += 1\n",
    "        while '###' not in v:   # no more edges for current node\n",
    "            if cnt % 100000 == 0:   # progress update\n",
    "                print('Edges added: ' + str(cnt))\n",
    "            if v == '':     # ignoring blank lines\n",
    "                cnt += 1\n",
    "                v = edgefile.readline().strip()\n",
    "                continue\n",
    "            if alias.get(v) is not None:    # if page redirects to another page\n",
    "                v = alias[v]\n",
    "            if nodeid.get(v) is None:    # assigning unique id to page for performance\n",
    "                nodeid[v] = last\n",
    "                nodename[last] = v\n",
    "                last += 1\n",
    "            v = nodeid[v]\n",
    "            adjlist[u].append(v)    # adding edge to adjacency list\n",
    "            v = edgefile.readline().strip()\n",
    "            cnt += 1\n",
    "    aliasfile.close()\n",
    "    edgefile.close()\n",
    "    global allnodes\n",
    "    allnodes = [c for c, c1 in adjlist.items()]     # list of all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def randomwalk(maxhops):    # runs a random walk of 'maxhops' steps\n",
    "    hops = 0\n",
    "    cur = random.choice(allnodes)   # starting node\n",
    "    if visits.get(cur) is None:     # visit counter for page rank\n",
    "        visits[cur] = 1\n",
    "    else:\n",
    "        visits[cur] += 1\n",
    "    while hops < maxhops:\n",
    "        if random.random() < 0.9:   # goes to a neighbour\n",
    "            if adjlist.get(cur) is None or len(adjlist[cur]) == 0:\n",
    "                cur = random.choice(allnodes)\n",
    "            else:   # if cur has no children\n",
    "                cur = random.choice(adjlist[cur])\n",
    "        else:   # goes to a random node\n",
    "            cur = random.choice(allnodes)\n",
    "        if visits.get(cur) is None:\n",
    "            visits[cur] = 1\n",
    "        else:\n",
    "            visits[cur] += 1\n",
    "        hops += 1\n",
    "        if hops % 1000000 == 0:     # progress tracker\n",
    "            print(str(round((hops / maxhops * 100), 2)) + ' %')\n",
    "\n",
    "\n",
    "def printlinks(ab):\n",
    "    ab = ab.lower().strip()\n",
    "    if alias.get(ab) is not None:\n",
    "        ab = alias[ab]\n",
    "    if adjlist.get(ab) is None:\n",
    "        print('page not found')\n",
    "        return\n",
    "    for c in adjlist[nodeid[ab]]:\n",
    "        print(nodename[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    init()\n",
    "    while True:\n",
    "        print('''Menu:\n",
    "        1 : Run a random walk of X hops\n",
    "        2 : Print the top K pages\n",
    "        3 : See all links of a particular page\n",
    "        Q : Quit'''\n",
    "        )\n",
    "        ip = input()\n",
    "        if ip == '1':\n",
    "            print('Enter number of hops: ')\n",
    "            maxhops = int(input())\n",
    "            randomwalk(maxhops)\n",
    "        elif ip == '2':\n",
    "            print('Enter number of top pages to be displayed')\n",
    "            k = int(input())\n",
    "            for a, b in sorted(visits.items(), key=lambda vk: (vk[1], vk[0]), reverse=True)[0:k]:\n",
    "                print(nodename[a])\n",
    "        elif ip == '3':\n",
    "            print('Enter page name to look for: ')\n",
    "            printlinks(input())\n",
    "        elif ip == 'Q':\n",
    "            print('Exiting')\n",
    "            break\n",
    "        else:\n",
    "            print('Invalid input')\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Displays all countries according to their page rank on Wikipedia\n",
    "pageranklist = sorted(visits.items(), key = lambda vk : (vk[1], vk[0]), reverse= True)\n",
    "country = '''Afghanistan\n",
    "Albania\n",
    "Algeria\n",
    "Andorra\n",
    "Angola\n",
    "Antigua and Barbuda\n",
    "Argentina\n",
    "Armenia\n",
    "Australia\n",
    "Austria\n",
    "Azerbaijan\n",
    "The Bahamas\n",
    "Bahrain\n",
    "Bangladesh\n",
    "Barbados\n",
    "Belarus\n",
    "Belgium\n",
    "Belize\n",
    "Benin\n",
    "Bhutan\n",
    "Bolivia\n",
    "Bosnia and Herzegovina\n",
    "Botswana\n",
    "Brazil\n",
    "Brunei\n",
    "Bulgaria\n",
    "Burkina Faso\n",
    "Burundi\n",
    "Cambodia\n",
    "Cameroon\n",
    "Canada\n",
    "Cape Verde\n",
    "Central African Republic\n",
    "Chad\n",
    "Chile\n",
    "China\n",
    "Colombia\n",
    "Comoros\n",
    "Republic of the Congo\n",
    "Democratic Republic of the Congo\n",
    "Costa Rica\n",
    "Ivory Coast\n",
    "Croatia\n",
    "Cuba\n",
    "Cyprus\n",
    "Czech Republic\n",
    "Denmark\n",
    "Djibouti\n",
    "Dominica\n",
    "Dominican Republic\n",
    "East Timor\n",
    "Ecuador\n",
    "Egypt\n",
    "El Salvador\n",
    "Equatorial Guinea\n",
    "Eritrea\n",
    "Estonia\n",
    "Ethiopia\n",
    "Fiji\n",
    "Finland\n",
    "France\n",
    "Gabon\n",
    "The Gambia\n",
    "Georgia\n",
    "Germany\n",
    "Ghana\n",
    "Greece\n",
    "Grenada\n",
    "Guatemala\n",
    "Guinea\n",
    "Guinea-Bissau\n",
    "Guyana\n",
    "Haiti\n",
    "Honduras\n",
    "Hungary\n",
    "Iceland\n",
    "India\n",
    "Indonesia\n",
    "Iran\n",
    "Iraq\n",
    "Ireland\n",
    "Israel\n",
    "Italy\n",
    "Jamaica\n",
    "Japan\n",
    "Jordan\n",
    "Kazakhstan\n",
    "Kenya\n",
    "Kiribati\n",
    "North Korea\n",
    "South Korea\n",
    "Kosovo\n",
    "Kuwait\n",
    "Kyrgyzstan\n",
    "Laos\n",
    "Latvia\n",
    "Lebanon\n",
    "Lesotho\n",
    "Liberia\n",
    "Libya\n",
    "Liechtenstein\n",
    "Lithuania\n",
    "Luxembourg\n",
    "Macedonia\n",
    "Madagascar\n",
    "Malawi\n",
    "Malaysia\n",
    "Maldives\n",
    "Mali\n",
    "Malta\n",
    "Marshall Islands\n",
    "Mauritania\n",
    "Mauritius\n",
    "Mexico\n",
    "Federated States of Micronesia\n",
    "Moldova\n",
    "Monaco\n",
    "Mongolia\n",
    "Montenegro\n",
    "Morocco\n",
    "Mozambique\n",
    "Myanmar\n",
    "Namibia\n",
    "Nauru\n",
    "Nepal\n",
    "Netherlands\n",
    "New Zealand\n",
    "Nicaragua\n",
    "Niger\n",
    "Nigeria\n",
    "Norway\n",
    "Oman\n",
    "Pakistan\n",
    "Palau\n",
    "Panama\n",
    "Papua New Guinea\n",
    "Paraguay\n",
    "Peru\n",
    "Philippines\n",
    "Poland\n",
    "Portugal\n",
    "Qatar\n",
    "Romania\n",
    "Russia\n",
    "Rwanda\n",
    "Saint Kitts and Nevis\n",
    "Saint Lucia\n",
    "Saint Vincent and the Grenadines\n",
    "Samoa\n",
    "San Marino\n",
    "São Tomé and Príncipe\n",
    "Saudi Arabia\n",
    "Senegal\n",
    "Serbia\n",
    "Seychelles\n",
    "Sierra Leone\n",
    "Singapore\n",
    "Slovakia\n",
    "Slovenia\n",
    "Solomon Islands\n",
    "Somalia\n",
    "South Africa\n",
    "South Sudan\n",
    "Spain\n",
    "Sri Lanka\n",
    "Sudan\n",
    "Suriname\n",
    "Swaziland\n",
    "Sweden\n",
    "Switzerland\n",
    "Syria\n",
    "Taiwan\n",
    "Tajikistan\n",
    "Tanzania\n",
    "Thailand\n",
    "Togo\n",
    "Tonga\n",
    "Trinidad and Tobago\n",
    "Tunisia\n",
    "Turkey\n",
    "Turkmenistan\n",
    "Tuvalu\n",
    "Uganda\n",
    "Ukraine\n",
    "United Arab Emirates\n",
    "United Kingdom\n",
    "United States\n",
    "Uruguay\n",
    "Uzbekistan\n",
    "Vanuatu\n",
    "Vatican City\n",
    "Venezuela\n",
    "Vietnam\n",
    "Yemen\n",
    "Zambia\n",
    "Zimbabwe'''\n",
    "countrylist = []\n",
    "for line in country.split('\\n'):\n",
    "    countrylist.append(line.strip().lower())\n",
    "for a, b in pageranklist:\n",
    "    if nodename[a] in countrylist:\n",
    "        print(nodename[a], b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# average and minimum hops required to go from page1 to page2 with a random walk\n",
    "def randomwalkhops(cur):\n",
    "    hops = 0\n",
    "    while cur!= nodeid['tom cruise'.lower()]:\n",
    "        if random.random() < 0.9:\n",
    "            if adjlist.get(cur) is None or len(adjlist[cur]) == 0:\n",
    "                cur = random.choice(allnodes)\n",
    "            else:\n",
    "                cur = random.choice(adjlist[cur])\n",
    "        else:\n",
    "            cur = random.choice(allnodes)\n",
    "        hops += 1\n",
    "    return hops\n",
    "avghops = 0\n",
    "minhops = 2e9\n",
    "runs = 100 # number of random walks to conduct\n",
    "startnode = 'tom hanks'     #set starting node\n",
    "endnode = 'jerry seinfeld'      #set ending node\n",
    "randomwalk(10000000)\n",
    "for i in range(runs):\n",
    "    startnode = startnode.strip().lower()\n",
    "    endnode = endnode.strip().lower()\n",
    "    if nodeid.get(startnode) is None:\n",
    "        print(startnode + ' does not exist')\n",
    "    elif nodeid.get(endnode) is None:\n",
    "        print(endnode + ' does not exist')\n",
    "    else:\n",
    "        hops = randomwalkhops(startnode)\n",
    "        avghops += hops/runs\n",
    "        minhops = min(minhops, hops)\n",
    "print(avghops, minhops)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
